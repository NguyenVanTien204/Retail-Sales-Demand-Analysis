{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c8b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Install psutil if not available\n",
    "try:\n",
    "    import psutil\n",
    "except ImportError:\n",
    "    !pip install psutil\n",
    "    import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9d4ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./Data/Parquet/star_schema_daily\"  # Data\\Parquet\\star_schema_daily\n",
    "PATHS = {\n",
    "    \"dim_item\": os.path.join(DATA_DIR, \"dim_item.parquet\"),\n",
    "    \"dim_store\": os.path.join(DATA_DIR, \"dim_store.parquet\"),\n",
    "    \"dim_state\": os.path.join(DATA_DIR, \"dim_state.parquet\"),\n",
    "    \"dim_calendar\": os.path.join(DATA_DIR, \"dim_calendar.parquet\"),\n",
    "    \"fact_sales\": os.path.join(DATA_DIR, \"fact_sales.parquet\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7558ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_item = pl.scan_parquet(PATHS[\"dim_item\"])\n",
    "dim_store = pl.scan_parquet(PATHS[\"dim_store\"])\n",
    "dim_state = pl.scan_parquet(PATHS[\"dim_state\"])\n",
    "dim_cal = pl.scan_parquet(PATHS[\"dim_calendar\"]).with_columns(pl.col(\"date_id\").cast(pl.Date))\n",
    "fact = pl.scan_parquet(PATHS[\"fact_sales\"]).with_columns(pl.col(\"date_id\").cast(pl.Date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ca7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# đảm bảo date_id là Date - di chuyển xuống sau join\n",
    "# dim_cal = dim_cal.with_columns(pl.col(\"date_id\").cast(pl.Date))\n",
    "# fact = fact.with_columns(pl.col(\"date_id\").cast(pl.Date))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d502b89b",
   "metadata": {},
   "source": [
    "# ----------- Thứ 2 (03/10/2025) -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fde4e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Join dim info vào fact để tiện xử lý ---\n",
    "fact = (\n",
    "    fact.join(dim_item.select([\"item_id\", \"dept_id\", \"cat_id\", \"price\"]).with_columns(\n",
    "        pl.col(\"price\").cast(pl.Float64)\n",
    "    ), on=\"item_id\", how=\"left\")\n",
    "    .join(dim_store.select([\"store_id\", \"state_id\", \"type\", \"size\"]), on=\"store_id\", how=\"left\")\n",
    "    .join(dim_cal.select([\"date_id\", \"weekday\", \"day_of_month\", \"month\", \"year\", \"week_id\", \"event_name\", \"event_type\",\n",
    "                          \"snap_CA\", \"snap_TX\", \"snap_WI\"]), on=\"date_id\", how=\"left\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f028bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time features, lags, rolling\n",
    "# đảm bảo date_id là Date\n",
    "fact = fact.with_columns(pl.col(\"date_id\").cast(pl.Date))\n",
    "\n",
    "def create_time_features(df: pl.LazyFrame) -> pl.LazyFrame:\n",
    "    # basic time features\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"weekday\").alias(\"weekday\"),  # từ dim_calendar nếu có\n",
    "        pl.col(\"month\").alias(\"month\"),\n",
    "        pl.col(\"year\").alias(\"year\"),\n",
    "        (pl.col(\"date_id\").dt.week()).alias(\"week_of_year\")\n",
    "    ])\n",
    "    # holiday flag (từ event_name/event_type)\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"event_name\").is_not_null() & (pl.col(\"event_name\") != \"\")).alias(\"is_holiday_event\"),\n",
    "        (pl.col(\"event_type\").is_not_null() & (pl.col(\"event_type\") != \"\")).alias(\"is_event\"),\n",
    "        pl.col(\"snap_CA\").fill_null(False).alias(\"snap_CA\"),\n",
    "        pl.col(\"snap_TX\").fill_null(False).alias(\"snap_TX\"),\n",
    "        pl.col(\"snap_WI\").fill_null(False).alias(\"snap_WI\")\n",
    "    ])\n",
    "    return df\n",
    "\n",
    "fact = create_time_features(fact)\n",
    "# Select only necessary columns to reduce memory\n",
    "fact = fact.select([\n",
    "    \"item_id\", \"store_id\", \"date_id\", \"units_sold\", \"revenue\",\n",
    "    \"dept_id\", \"cat_id\", \"price\", \"state_id\", \"type\", \"size\",\n",
    "    \"weekday\", \"day_of_month\", \"month\", \"year\", \"week_id\", \"week_of_year\",\n",
    "    \"event_name\", \"event_type\", \"is_holiday_event\", \"is_event\",\n",
    "    \"snap_CA\", \"snap_TX\", \"snap_WI\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa80947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unit_price for promotion detection\n",
    "fact = fact.with_columns(\n",
    "    (pl.when(pl.col(\"units_sold\") > 0)\n",
    "     .then(pl.col(\"revenue\") / pl.col(\"units_sold\"))\n",
    "     .otherwise(pl.lit(None))\n",
    "    ).alias(\"unit_price\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a055b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag features: shift by 1,7,28 days grouped by (item_id, store_id)\n",
    "LAGS = [1, 7, 28]\n",
    "for lag in LAGS:\n",
    "    fact = fact.with_columns([\n",
    "        pl.col(\"units_sold\").shift(lag).over([\"item_id\", \"store_id\"]).alias(f\"units_lag_{lag}\"),\n",
    "        pl.col(\"revenue\").shift(lag).over([\"item_id\", \"store_id\"]).alias(f\"revenue_lag_{lag}\"),\n",
    "        pl.col(\"unit_price\").shift(lag).over([\"item_id\", \"store_id\"]).alias(f\"unit_price_lag_{lag}\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a701e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling means: 7, 28, 90 (grouped by item-store), forward-looking excluded (use past window ending at t-1)\n",
    "ROLLS = [7, 28, 90]\n",
    "for w in ROLLS:\n",
    "    # polars rolling_mean expression with .over\n",
    "    # ensure data sorted within groups by date_id for correct rolling\n",
    "    fact = fact.sort([\"item_id\", \"store_id\", \"date_id\"])\n",
    "    fact = fact.with_columns([\n",
    "        pl.col(\"units_sold\").rolling_mean(window_size=w).over([\"item_id\", \"store_id\"]).alias(f\"units_roll_mean_{w}\"),\n",
    "        pl.col(\"revenue\").rolling_mean(window_size=w).over([\"item_id\", \"store_id\"]).alias(f\"revenue_roll_mean_{w}\")\n",
    "    ])\n",
    "\n",
    "# moving average short example (exponential not native - can approximate or use pandas if needed)\n",
    "# here use simple moving average is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ca9e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect to DataFrame before rolling operations to avoid lazy issues and optimize memory\n",
    "fact = fact.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ff23069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 2250.29 MB\n",
      "DataFrame shape: (58327370, 24)\n"
     ]
    }
   ],
   "source": [
    "# Check memory usage after collect\n",
    "import psutil\n",
    "import os\n",
    "process = psutil.Process(os.getpid())\n",
    "print(f\"Memory usage: {process.memory_info().rss / 1024 / 1024:.2f} MB\")\n",
    "print(f\"DataFrame shape: {fact.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "382bbfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu dữ liệu vào ./Data/Processed/fact_features.parquet\n",
      "Kích thước file: 0.31 GB\n"
     ]
    }
   ],
   "source": [
    "# Lưu dữ liệu đã xử lý\n",
    "output_path = \"./Data/Processed/fact_features.parquet\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "fact.write_parquet(output_path)\n",
    "print(f\"Đã lưu dữ liệu vào {output_path}\")\n",
    "print(f\"Kích thước file: {os.path.getsize(output_path) / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008f4e59",
   "metadata": {},
   "source": [
    "# ----------- Thứ 3 (04/10/2025) -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic: promotion if unit_price < (dim_item.price * 0.98)  (2% threshold)\n",
    "fact = fact.with_columns(\n",
    "    (pl.col(\"unit_price\") < (pl.col(\"price\") * 0.98)).alias(\"is_promo_price\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb9732",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact = fact.with_columns(pl.col(\"is_promo_price\").fill_null(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91996cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute promotion summary by item/store\n",
    "promo_summary = (\n",
    "    fact.groupby([\"item_id\", \"store_id\"])\n",
    "    .agg([\n",
    "        pl.mean(\"units_sold\").alias(\"avg_units\"),\n",
    "        pl.mean(\"revenue\").alias(\"avg_revenue\"),\n",
    "        pl.sum(\"is_promo_price\").alias(\"promo_days\"),\n",
    "        pl.count().alias(\"total_days\"),\n",
    "        (pl.col(\"promo_days\") / pl.col(\"total_days\")).alias(\"promo_ratio\")\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4851fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of promo: compare avg units on promo days vs non-promo days (global)\n",
    "promo_effect = (\n",
    "    fact.groupby(\"is_promo_price\")\n",
    "    .agg([\n",
    "        pl.mean(\"units_sold\").alias(\"mean_units\"),\n",
    "        pl.mean(\"revenue\").alias(\"mean_revenue\"),\n",
    "        pl.count().alias(\"days\")\n",
    "    ])\n",
    ").sort(\"is_promo_price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204be8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also analyze event/holiday effect:\n",
    "event_effect = (\n",
    "    fact.groupby(\"is_holiday_event\")\n",
    "    .agg([\n",
    "        pl.mean(\"units_sold\").alias(\"mean_units\"),\n",
    "        pl.mean(\"revenue\").alias(\"mean_revenue\"),\n",
    "        pl.count().alias(\"days\")\n",
    "    ])\n",
    ").sort(\"is_holiday_event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184d6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price elasticity rough calc per item: correlation between unit_price and units_sold per item (sample)\n",
    "# We'll compute for items with enough variance\n",
    "def price_units_corr(df):\n",
    "    # return DataFrame item_id, corr\n",
    "    # convert to pandas for correlation per group (simpler)\n",
    "    pdf = df.select([\"item_id\", \"unit_price\", \"units_sold\"]).to_pandas()\n",
    "    res = []\n",
    "    for item, g in pdf.groupby(\"item_id\"):\n",
    "        if g[\"unit_price\"].count() > 30 and g[\"unit_price\"].std() > 0:\n",
    "            corr = g[\"unit_price\"].corr(g[\"units_sold\"])\n",
    "            res.append((item, corr))\n",
    "    import pandas as pd\n",
    "    return pd.DataFrame(res, columns=[\"item_id\", \"price_units_corr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5734922b",
   "metadata": {},
   "source": [
    "# ----------- Thứ 4 (05/10/2025) -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2772eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series_total_units(df: pl.DataFrame, save_path=None):\n",
    "    # aggregate by date\n",
    "    ts = df.groupby(\"date_id\").agg(pl.sum(\"units_sold\").alias(\"total_units\")).sort(\"date_id\")\n",
    "    pdf = ts.to_pandas()\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.plot(pdf[\"date_id\"], pdf[\"total_units\"], label=\"total_units\")\n",
    "    # add rolling mean for visualization (30-day)\n",
    "    pdf[\"rolling_30\"] = pdf[\"total_units\"].rolling(30, min_periods=1).mean()\n",
    "    plt.plot(pdf[\"date_id\"], pdf[\"rolling_30\"], label=\"rolling_30\")\n",
    "    plt.title(\"Total Units Sold Over Time\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Units\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b03328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_seasonality(df: pl.DataFrame, cat_id, freq=\"M\", save_path=None):\n",
    "    # aggregate per month for a category\n",
    "    sub = df.filter(pl.col(\"cat_id\") == cat_id)\n",
    "    agg = sub.with_columns(pl.col(\"date_id\").dt.truncate(\"1mo\").alias(\"month\")).groupby(\"month\").agg(pl.sum(\"units_sold\").alias(\"units\"))\n",
    "    pdf = agg.sort(\"month\").to_pandas()\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(pdf[\"month\"], pdf[\"units\"], label=f\"cat_{cat_id}\")\n",
    "    pdf[\"roll_3\"] = pdf[\"units\"].rolling(3, min_periods=1).mean()\n",
    "    plt.plot(pdf[\"month\"], pdf[\"roll_3\"], label=\"3-month MA\")\n",
    "    plt.title(f\"Seasonality - Category {cat_id}\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Units\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95bf2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_correlation(df: pl.DataFrame, start_date=None, end_date=None, save_path=None):\n",
    "    # pivot: index = month, cols = cat_id, values = sum units\n",
    "    tmp = df.with_columns(pl.col(\"date_id\").dt.truncate(\"1mo\").alias(\"month\"))\n",
    "    agg = tmp.groupby([\"month\", \"cat_id\"]).agg(pl.sum(\"units_sold\").alias(\"units\"))\n",
    "    pivot = agg.pivot(values=\"units\", index=\"month\", columns=\"cat_id\").fill_null(0).sort(\"month\")\n",
    "    pdf = pivot.to_pandas().set_index(\"month\")\n",
    "    corr = pdf.corr()\n",
    "    # plot heatmap via matplotlib\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    c = ax.imshow(corr.values, aspect='auto')\n",
    "    ax.set_xticks(range(len(corr.columns)))\n",
    "    ax.set_xticklabels(corr.columns, rotation=90)\n",
    "    ax.set_yticks(range(len(corr.index)))\n",
    "    ax.set_yticklabels(corr.index)\n",
    "    fig.colorbar(c, ax=ax)\n",
    "    plt.title(\"Correlation matrix between categories (monthly aggregated units)\")\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4fc45d",
   "metadata": {},
   "source": [
    "# ----------- Thứ 5 (06/10/2025) -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_basic_insights(fact_df: pl.DataFrame):\n",
    "    insights = []\n",
    "    # top categories by total units\n",
    "    top_cats = fact_df.groupby(\"cat_id\").agg(pl.sum(\"units_sold\").alias(\"total_units\")).sort(\"total_units\", reverse=True).head(10)\n",
    "    insights.append((\"top_cats\", top_cats))\n",
    "    # top states by revenue\n",
    "    top_states = fact_df.groupby(\"state_id\").agg(pl.sum(\"revenue\").alias(\"total_revenue\")).sort(\"total_revenue\", reverse=True).head(10)\n",
    "    insights.append((\"top_states\", top_states))\n",
    "    # seasonality signal check: variance across months / mean\n",
    "    monthly = fact_df.with_columns(pl.col(\"date_id\").dt.truncate(\"1mo\").alias(\"month\")).groupby(\"month\").agg(pl.sum(\"units_sold\").alias(\"units\"))\n",
    "    pdf = monthly.to_pandas()\n",
    "    seasonality_coef = pdf[\"units\"].std() / (pdf[\"units\"].mean() + 1e-9)\n",
    "    insights.append((\"seasonality_coef\", seasonality_coef))\n",
    "    return insights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
